{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ What is statistical inference\r\n",
    "+ Hypothesis Testing\r\n",
    "+ Formulate H0 & alternate hypothesis\r\n",
    "+ Select a test statistic that can answer the question\r\n",
    "+ Sampling distribution of the test statistic under H0 (i.e. the distribution we would get from repeated sampling)\r\n",
    "+ Can we use common distributions to approximate the sampling distribution of the test statistic & under what conditions\r\n",
    "+ Calculate the probability of having values of the test statistic at least as extreme as the observed value under H0\r\n",
    "+ Draw conclusions\r\n",
    "+ Power & Significance & Effect size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ t-test\r\n",
    "+ linear regression & link with t-test\r\n",
    "+ ANOVA\r\n",
    "+ Chi-square\r\n",
    "+ F-statistic\r\n",
    "\r\n",
    "https://www.annualreviews.org/doi/pdf/10.1146/annurev.publhealth.23.100901.140546"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\r\n",
    "\r\n",
    "# Statistical Inference\r\n",
    "\r\n",
    "Probabilistic reasoning allows us to describe uncertainty. It is the process by which we go from measured data to probabilistic conclusions about what we might expect if we collected the same data again and draw more general conclusions from relatively few data or observations.\r\n",
    "\r\n",
    "Statistical inference involves taking your data to probabilistic conclusions about what you would expect if you took even more data, and you can make decisions based on these conclusions. Data are almost never exactly the same when acquired again, and probability allows us to say how much we expect them to vary.\r\n",
    "\r\n",
    "Given a set of data, statistical inference describe probabilistically what you might expect if those data were acquired again. Repeating measurements provide an indication of the range of values we can expect the value of interest can take.\r\n",
    "\r\n",
    "If the observed data follows a common distribution, we can use its properties to infer conclusions about unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "> EDA can never be the whole story, but nothing else can serve as the foundation stone.\n",
    "\n",
    "> \\- John Tukey. \n",
    "\n",
    "Graphical EDA presents the information in a way that is easily interpretable. It guides the actions to take for hypothesis testing:\n",
    "+ The greatest value of a picture is that it forces us to notice what we never expected to see.\n",
    "+ It is important to understand what you can do before you learn how to measure how well you seem to have done it.\n",
    "+ If done well, graphical representations can allow for more rapid interpretation of data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# Parameter Estimation\n",
    "\n",
    "## Bootstrap Samples\n",
    "\n",
    "If we believe the process that generates our data follows a given probability distribution, a major goal of statistical inference is to estimate the values of these parameters, which allows us to concisely and unambiguously describe our data and draw conclusions from it. The optimal parameters for the model are directly computed from the data itself.\n",
    "\n",
    "Slight variations in the measured data would lead to slightly different parameters. We can simulate getting new data (i.e. what we would get from an infinitude of experiments) by bootstrapping: resampling our data with replacement and recomputing the parameter(s) of interest. We can plot the ECDF of the generated summary statistics to get the probability distribution of the parameter.\n",
    "\n",
    "+ each new sample is called a bootstrap sample.\n",
    "+ its summary statistics is called a bootstrap replicate.\n",
    "\n",
    "We can also calculate confidence intervals of the statistics. If we repeated measurements over and over again, p% of the observed values would lie within the p% confidence interval.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# Hypothesis Testing\n",
    "\n",
    "You now know how to define and estimate parameters of a given model. But the question remains: how reasonable is it that our observed data are actually described by our model? Hypothesis testing is an assessment of how reasonable the observed data are assuming a hypothesis is true; it is called the null hypothesis.\n",
    "\n",
    "What about the data do we assess, and how do we quantify the assessment? We use a test statistic: a single number that can be computed from observed data and from the data you generate under the null hypothesis. It serves as a basis of comparison between what the null hypothesis predicts and what we actually observed.\n",
    "\n",
    "_Note: the test statistic should be relevant to the question you are trying to answer._\n",
    "\n",
    "_Note2: Hypothesis testing is sometimes called Null Hypothesis Significance Testing or NHST._\n",
    "\n",
    "## Permutation Samples\n",
    "\n",
    "We could plot ECDFs or compare summary statistics. Another approach when comparing two samples is to combine data from both samples, scramble them and split the results in two samples that have the same size as the original ones. This simulates a null hypothesis where we assume the two quantities are identically distributed. The two resulting samples are called permutation samples.\n",
    "\n",
    "We can repeat the permutations many times to get the distribution of the difference in test statistics between the two samples under the null hypothesis. We can then calculate the percentatge of permutations that are more extreme than the observed data (i.e. the probability of having data at least as extreme as the observed value under the null hypothesis): the p-value.\n",
    "\n",
    "The p-value is NOT the probability that the null hypothesis is true, and is only valid if both the null hypothesis and the test statistic used to evaluate it are clearly stated.\n",
    "\n",
    "If the p-value is small (typically under 5%), the data is considered statistically significantly different than what we would observe under the null hypothesis.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 32-bit",
   "name": "python38032bit64a64ed7a47843b8be3706a54e9a0958"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}